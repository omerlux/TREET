{
    //"training"
    /* Training related parameters */
    "is_training": 1, // status
    "train_epochs": 50, // train epochs
    "batch_size": 1024, // batch size of train input data
    "patience": 10, // early stopping patience
    "learning_rate": 0.0001, // optimizer learning rate
    "loss": "dv", // loss function
    "lradj": "type1_0.9", // adjust learning rate
    "use_amp": false, // use automatic mixed precision training
    "optimizer": "adam", // optimizer name, options: [adam, rmsprop]
    "n_draws": 1, // number of draws for DV potential calculation
    "exp_clipping": "inf", // exponential clipping for DV potential calculation
    "alpha_dv_reg": 0.0, // alpha for DV regularization on C constant
    "num_workers": 0, // data loader num workers
    "itr": 1, // experiments times
    "log_interval": 5, // training log print interval

    //"model"
    /* Model related parameters */
    "model": "Decoder_Model", // model name, options: [Transformer_Encoder, LSTM, Autoformer, Informer, Transformer]
    "seq_len": 0, // input sequence length
    "label_len": 29, // start token length. pre-prediction sequence length for the encoder
    "pred_len": 30, // prediction sequence length
    "y_dim": 3, // y input size - exogenous values
    "x_dim": 3, // x input size - endogenous values
    "c_out": 1, // output size
    "d_model": 64, // dimension of model
    "n_heads": 1, // num of heads
    "time_layers": 1, // num of attention layers
    "ff_layers": 2, // num of ff layers
    "d_ff": 256, // dimension of fcn
    "factor": 1, // attn factor (c hyper-parameter)
    "distil": true, // whether to use distilling in encoder, using this argument means not using distilling
    "dropout": 0.0, // dropout
    "embed": "fixed", // time features encoding, options:[timeF, fixed, learned]
    "activation": "gelu", // activation - must be elu to work with NDG
    "output_attention": false, // whether to output attention in encoder

    //"process_channel"
    /* Process and Channel related parameters */
    "use_ndg": false, // use NDG instead of previous created dataset.
    "process_info": {
        "type": "AWGN",
        "sigma_x": 1,       // power of each element in the process - P_i
        "sigma_noise": 1,
        "n_samples": 900000, // sequence length of the process (according to the data)
        "memory_cut": false, // data stride - for RNN its recommended to be false. Transformer can be set to false
    }, // process information, for AWGN sigma_x,sigma_n are the stds.

    // "experiment"
    /* Experiment related parameters */
    "wandb": false, // activating wandb updates
    "save": "TMP", // name of main directory
    "model_id": "EXP", // model id
    "seed": 2021, // seed number
    "checkpoints": "checkpoints", // location of model checkpoints
    "use_gpu": true, // use gpu - if mentioned in args, no gpu
    "devices": "1", // device ids of multile gpus
}
